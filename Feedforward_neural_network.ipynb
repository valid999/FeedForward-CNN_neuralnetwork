{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60ZFaRHs5x49",
        "outputId": "21495fa3-9785-40c0-da21-4bec7bcd8c4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 24033578.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../../data/MNIST/raw/train-images-idx3-ubyte.gz to ../../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 48590330.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 15049072.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 14345277.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../../data/MNIST/raw\n",
            "\n",
            "Epoch [1/3] , Step[100/600] , Loss: 0.2321\n",
            "Epoch [1/3] , Step[200/600] , Loss: 0.2399\n",
            "Epoch [1/3] , Step[300/600] , Loss: 0.2224\n",
            "Epoch [1/3] , Step[400/600] , Loss: 0.1135\n",
            "Epoch [1/3] , Step[500/600] , Loss: 0.1595\n",
            "Epoch [1/3] , Step[600/600] , Loss: 0.1099\n",
            "Epoch [2/3] , Step[100/600] , Loss: 0.3101\n",
            "Epoch [2/3] , Step[200/600] , Loss: 0.0860\n",
            "Epoch [2/3] , Step[300/600] , Loss: 0.0564\n",
            "Epoch [2/3] , Step[400/600] , Loss: 0.1257\n",
            "Epoch [2/3] , Step[500/600] , Loss: 0.0982\n",
            "Epoch [2/3] , Step[600/600] , Loss: 0.1546\n",
            "Epoch [3/3] , Step[100/600] , Loss: 0.0366\n",
            "Epoch [3/3] , Step[200/600] , Loss: 0.0661\n",
            "Epoch [3/3] , Step[300/600] , Loss: 0.1675\n",
            "Epoch [3/3] , Step[400/600] , Loss: 0.0439\n",
            "Epoch [3/3] , Step[500/600] , Loss: 0.0667\n",
            "Epoch [3/3] , Step[600/600] , Loss: 0.0317\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "# Device configration\n",
        "device = torch.device('cuda' if torch.cuda.is_available()  else 'cpu')\n",
        "\n",
        "\n",
        "\n",
        "# Hyper-parameters\n",
        "input_size = 784\n",
        "hidden_size = 500\n",
        "num_classes = 10\n",
        "num_epochs = 3\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "# MNIST dataset\n",
        "train_dataset  = torchvision.datasets.MNIST(root = '../../data',\n",
        "                                           train  = True,\n",
        "                                           transform = transforms.ToTensor(),\n",
        "                                           download = True\n",
        "                                           )\n",
        "test_dataset = torchvision.datasets.MNIST(root = '../../data',\n",
        "                                          train = False ,\n",
        "                                          transform =  transforms.ToTensor()\n",
        "                                          )\n",
        "\n",
        "\n",
        "# Data Loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset ,\n",
        "                                           batch_size = batch_size ,\n",
        "\n",
        "                                           shuffle = True\n",
        "\n",
        "                                           )\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "# Fully connected neural network with one hidden layer\n",
        "# This model iws only a feed forward neural network\n",
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self , input_size , hidden_size , num_classes):\n",
        "    super(NeuralNet , self).__init__()\n",
        "    self.fc1 = nn.Linear(input_size , hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.fc2 = nn.Linear(hidden_size , num_classes)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self , x):\n",
        "    out = self.fc1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.fc2(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model = NeuralNet(input_size , hidden_size , num_classes).to(device)\n",
        "\n",
        "# Losss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters() , lr = learning_rate)\n",
        "\n",
        "\n",
        "\n",
        "# Train the model\n",
        "# total the model\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "  for i , (image , labels) in enumerate(train_loader):\n",
        "    # Move tensor to the configured device\n",
        "    images = image.reshape(-1 , 28*28).to(device) # Orginal shape ([100 , 1 , 28 , 28])\n",
        "    label = labels.to(device)\n",
        "\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs , label)\n",
        "\n",
        "\n",
        "    # Backward and optimize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1) % 100 == 0 :\n",
        "      print('Epoch [{}/{}] , Step[{}/{}] , Loss: {:.4f}'.format(epoch+1 , num_epochs , i+1 , total_step , loss.item()))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The orginal shape of the images\n",
        "\n",
        "for i, (images, labels) in enumerate(train_loader):\n",
        "        # Move tensors to the configured device\n",
        "        images = images.shape\n",
        "        print(images)\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddiTRV_j-3iG",
        "outputId": "d53b6d1d-1a7b-4f89-84ac-b2c1fa86045c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_example(img , label):\n",
        "  plt.show(img.permute(1 , 2 , 0))"
      ],
      "metadata": {
        "id": "2wJ452D7DPOm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  for images , labels in test_loader:\n",
        "    images = images.reshape(-1 , 784).to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "    _ , predicted = torch.max(outputs.data , 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  print('Accuracy of the network on the 10000 test images : {} %'.format(100 * correct / total))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPWDiDV--5ps",
        "outputId": "b4a6b532-d9a1-447e-b3e4-b93981f56c2a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images : 97.51 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for img_batch , label_batch in train_loader:\n",
        "  print('first batch')\n",
        "  print(img_batch.shape)\n",
        "  plt.imshow(img_batch[0][0] , cmap = 'gray')\n",
        "  print(label_batch)\n",
        "  print(type(img_batch))\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "-JuUH8ivFudw",
        "outputId": "6fb82f9a-7190-42c4-d9ca-3eb8cc70deed"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first batch\n",
            "torch.Size([100, 1, 28, 28])\n",
            "tensor([0, 2, 9, 2, 2, 4, 5, 3, 0, 5, 5, 0, 6, 8, 7, 0, 8, 4, 3, 3, 1, 6, 9, 9,\n",
            "        0, 5, 2, 6, 4, 2, 3, 7, 8, 9, 3, 5, 6, 8, 4, 6, 6, 3, 9, 9, 5, 7, 3, 9,\n",
            "        3, 2, 9, 1, 7, 0, 3, 1, 5, 6, 7, 8, 5, 1, 2, 1, 0, 5, 4, 1, 7, 7, 6, 4,\n",
            "        3, 6, 5, 7, 7, 0, 8, 9, 3, 4, 5, 4, 0, 4, 6, 0, 4, 1, 3, 0, 6, 0, 4, 9,\n",
            "        2, 8, 7, 6])\n",
            "<class 'torch.Tensor'>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model checkpoint\n",
        "torch.save(model.state_dict() , 'model.ckpt')"
      ],
      "metadata": {
        "id": "rxWbGriIIfaf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def predict_image(img, model):\n",
        "    xb = img.unsqueeze(0)\n",
        "    yb = model(xb)\n",
        "    _, preds = torch.max(yb, dim=1)\n",
        "    return preds[0].item()"
      ],
      "metadata": {
        "id": "nB3rykfBIoiO"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for img, label in test_loader:\n",
        "\n",
        "#   plt.imshow(img[0][0], cmap='gray')\n",
        "#   print('Label:', label, ', Predicted:', predict_image(img, model))"
      ],
      "metadata": {
        "id": "SyW5E_0cLFVb"
      },
      "execution_count": 35,
      "outputs": []
    }
  ]
}